---
title: "分布式缓存——毛剑Go训练营回顾"
date: 2022-11-04T14:17:31+08:00
draft: false
tags: ["memcache","redis","redis cluster","一致性hash","缓存穿透","热点缓存"]
categories: ["缓存","分布式"]
topics: ["分布式缓存","毛剑Go训练营回顾"]
cover:
---

# 缓存选型

## memcache

memcache提供简单的kv cache存储，value大小不超过1mb。memcache通常作为大文本或者简单的kv结构使用。

memcache使用了slab方式作内存管理，存在一定的浪费，如果大量接近的item，建议调整memcache参数来优化每一个slab增长的ratio、可以通过设置slab_automove&slab_reassign开启memcache的动态/手动move slab，防止某些slab热点导致内存足够的情况下引发LRU。

![](/images/分布式缓存/memcache.png)

## redis

redis拥有丰富的数据类型，支持增量方式修改部分数据，比如排行榜、集合、数组等。

常用的方式是使用redis作为数据索引。

redis因为没有使用内存池，是存在一定的内存碎片的，一般使用jemalloc来优化内存分配，需要编译时使用jemalloc库代理glib的malloc使用。

## redis vs memcache

最大的区别在于redis单线程（新版本双线程），memcache多线程，所以QPS两者差异不大，但是吞吐会有很大的差别，比如大数据value返回的时候，redis qps会抖动下降的很厉害，因为单线程工作，其他查询进不来。

建议纯kv存储使用memcache，也可以使用memcache+redis双缓存设计。

redis社区活跃，迭代速度快，后续可能完全取代memcache。

## Proxy

- codis: 只支持redis协议，且需要使用patch版本的redis。
- mcrouter: 只支持memcache协议，C开发，运维集成开发难度高。

### 使用方式

通过Sidecar方式使用。

## redis cluster

### 一致性hash

一致性hash是将数据按照特征值映射到一个首位相接的hash环上，同时也将节点（按照IP地址或者机器名hash）映射到这个环上。

对于数据，从数据在环上的位置开始，顺时针找到的第一个节点即位数据的存储节点。

余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在园（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响。

![](/images/分布式缓存/一致性hash.png)

- `平衡性`：尽可能分布到所有的缓冲中。
- `单调性`：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中，而不会被映射到旧的缓冲集合中的其他缓冲区。
- `分散性`：相同内容被存储到不同的缓冲中去，降低了系统存储的效率，需要尽量降低分散性。
- `负载`：哈希算法应能够尽量降低缓冲的负荷。
- `平滑性`：缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

一致性哈希算法在服务节点太少时，容易因为节点分布不均匀造成数据倾斜问题。因此一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。

![](/images/分布式缓存/虚拟节点.png)

### slot

redis-cluster把16384槽按照节点数量进行平均分配，由节点进行管理。

对每个key按照CRC16规则进行hash运算，把hash结果对16384进行取余，把余数发送给redis节点。

redis cluster的节点之间会共享消息，每个节点都会知道谁哪个节点负责哪个范围内的数据槽。

# 缓存模式

## 数据一致性

Storage和Cache同步更新容易出现数据不一致。

    读/写同时操作:

    1. 读操作，读缓存，缓存 MISS
    2. 读操作，读 DB，读取到数据
    3. 写操作，更新 DB 数据
    4. 写操作 SET/DELETE Cache（可 Job 异步操作）
    5. 读操作，SET操作数据回写缓存（可 Job 异步操作）

    这种交互下，由于4和5操作步骤都是设置缓存，导致写入的值互相覆盖；并且操作的顺序性不确定，从而导致 cache 存在脏缓存的情况。

解决方式:

    读/写同时操作:

    1. 读操作，读缓存，缓存 MISS
    2. 读操作，读 DB，读取到数据
    3. 写操作，更新 DB 数据
    4. 写操作 SET Cache（可异步 job 操作，Redis 可以使用 SETEX 操作）
    5. 读操作，ADD 操作数据回写缓存（可 Job异步操作，Redis 可以使用 SETNX 操作）

    写操作使用 SET 操作命令，覆盖写缓存；读操作，使用 ADD 操作回写 MISS 数据，从而保证写操作的最新数据不会被读操作的回写数据覆盖。

最好使用更新Storage时对Cache使用DELETE操作的方式进行缓存。

## 多级缓存

微服务拆分细粒度原子业务下的整合服务（聚合服务），用于提供粗粒度的接口，以及二级缓存加速，减少扇出的 rpc 网络请求，减少延迟。

最重要是保证多级缓存的一致性：

- 清理的优先级是有要求的，先优先清理下游再上游

- 下游的缓存expire要大于上游，里面穿透回源

## 热点缓存

对于热点缓存Key，按照如下思路解决:

- 小表广播，从RemoteCache提升为LocalCache，App定时更新，甚至可以让运营平台支持广播刷新LocalCache。
- 主动监控防御预热。
- 基础库框架支持热点发现，自动短时的short-live cache。
- 多Cluster支持: redis-cluster主从集群，从集群支持读操作。
- 多Key设计: 使用多副本，减小节点热点的问题。（写放大，缓存清理时所有节点都要清理）

## 穿透缓存

- singlefly

    对关键字进行一致性 hash，使其某一个维度的 key 一定命中某个节点，然后在节点内使用互斥锁，保证归并回源，但是对于批量查询无解；
- 分布式锁(不建议使用)
  
    设置一个 lock key，有且只有一个人成功，并且返回，交由这个人来执行回源操作，其他候选者轮训 cache 这个 lock key，如果不存在去读数据缓存，hit 就返回，miss 继续抢锁；
- 队列
  
    如果 cache miss，交由队列聚合一个key，来 load 数据回写缓存，对于 miss 当前请求可以使用 singlefly 保证回源，如评论架构实现。适合回源加载数据重的任务，比如评论 miss 只返回第一页，但是需要构建完成评论数据索引。
- lease（租约）
  
    通过加入 lease 机制，可以很好避免这两个问题，lease 是 64-bit 的 token，与客户端请求的 key 绑定，对于过时设置，在写入时验证 lease，可以解决这个问题；对于 thundering herd，每个key 10s 分配一次，当 client 在没有获取到 lease 时，可以稍微等一下再访问 cache，这时往往cache 中已有数据。（基础库支持 & 修改 cache 源码）；

# 缓存技巧

- 易读性的前提下，key 设置尽可能小，减少资源的占用，redis value 可以用 int 就不要用string，对于小于 N 的 value，redis 内部有 shared_object 缓存。
- 拆分 key。主要是用在 redis 使用 hashes 情况下。同一个 hashes key 会落到同一个 redis 节点，hashes 过大的情况下会导致内存及请求分布的不均匀。考虑对 hash 进行拆分为小的hash，使得节点内存均匀及避免单节点请求热点。
- 空缓存设置。对于部分数据，可能数据库始终为空，这时应该设置空缓存，避免每次请求都缓存 miss 直接打到 DB。
- 空缓存保护策略。
- 读失败后的写缓存策略（降级后一般读失败不触发回写缓存）。
- 序列化使用 protobuf，尽可能减少 size。
- 工具化浇水代码

## memcache小技巧

- flag 使用：标识 compress、encoding、large value 等；
- memcache 支持 gets，尽量读取，尽可能的 pipeline，减少网络往返；
- 使用二进制协议，支持 pipeline delete，UDP 读取、TCP 更新；

## redis小技巧

- 增量更新一致性：EXPIRE、ZADD/HSET 等，保证索引结构体务必存在的情况下去操作新增数据；
- BITSET: 存储每日登陆用户，单个标记位置（boolean），为了避免单个 BITSET 过大或者热点，需要使用 region sharding，比如按照mid求余 %和/ 10000，商为 KEY、余数作为offset；
- List:抽奖的奖池、顶弹幕，用于类似 Stack PUSH/POP操作；
- Sortedset: 翻页、排序、有序的集合，杜绝 zrange 或者 zrevrange 返回的集合过大；
- Hashs: 过小的时候会使用压缩列表、过大的情况容易导致 rehash 内存浪费，也杜绝返回hgetall，对于小结构体，建议直接使用 memcache KV；
- String: SET 的 EX/NX 等 KV 扩展指令，SETNX 可以用于分布式锁、SETEX 聚合了SET + EXPIRE；
- Sets: 类似 Hashs，无 Value，去重等；
- 尽可能的 PIPELINE 指令，但是避免集合过大；
- 避免超大 Value；

# RefReference

https://blog.csdn.net/chen_kkw/article/details/82724330

https://zhuanlan.zhihu.com/p/328728595

https://www.cnblogs.com/chinanetwind/articles/9460820.html

https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed

https://www.jianshu.com/p/5fa447c60327

https://writings.sh/post/consistent-hashing-algorithms-part-1-the-problem-and-the-concept

https://www.cnblogs.com/williamjie/p/11132211.html